{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01fb341-2555-4917-a41e-3e098258a6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/aton/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/aton/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/aton/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/aton/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/aton/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b92938a-56d1-4a0d-ace5-0bb9590d9962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Obtaining dependency information for ucimlrepo from https://files.pythonhosted.org/packages/3b/07/1252560194df2b4fad1cb3c46081b948331c63eb1bb0b97620d508d12a53/ucimlrepo-0.0.7-py3-none-any.whl.metadata\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/aton/anaconda3/lib/python3.11/site-packages (from ucimlrepo) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /Users/aton/anaconda3/lib/python3.11/site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aton/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aton/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/aton/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/aton/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aton/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Using cached ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1be5d59a-bf29-4527-a295-939ca30c4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6b86972a-830a-4968-b946-5008083a0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "\n",
    "# metadata \n",
    "#print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "#print(breast_cancer_wisconsin_diagnostic.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a406d097-9b57-42a1-8276-86cd0fc9dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split data into features (X) and target (y) (quality)\n",
    "\n",
    "# Make data into matrices\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "#change so 0 is negative, 1 is positive\n",
    "y = np.where(y == 'M', 0, 1)\n",
    "# Normalize\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X = (X-X_mean) / X_std\n",
    "\n",
    "# add w0 element\n",
    "n,m = X.shape\n",
    "X0 = np.ones((n,1))\n",
    "X = np.hstack((X0,X))\n",
    "\n",
    "# 80% for training+validation and 20% for testing\n",
    "X_train_val, X_testM, y_train_val, y_testM = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# The 80% (training+validation) into 60% for training and 20% for validation\n",
    "X_trainM, X_valM, y_trainM, y_valM = train_test_split(X_train_val, y_train_val, test_size=0.20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "39adfa3e-6416-4e86-bf0e-e14c0d7226ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total class 1 in train: [238] ([61.65803109]%)\n",
      "Total class 1 in validation: [65] ([67.01030928]%)\n",
      "Training set size: (386, 31)\n",
      "Validation set size: (97, 31)\n",
      "Test set size: (86, 31)\n"
     ]
    }
   ],
   "source": [
    "rows, cols = y_trainM.shape\n",
    "totalpositive =0\n",
    "for i in range(rows):\n",
    "    totalpositive += y_trainM[i]\n",
    "\n",
    "print(f\"Total class 1 in train: {totalpositive} ({100*totalpositive/rows}%)\")\n",
    "\n",
    "rows, cols = y_valM.shape\n",
    "totalpositive =0\n",
    "for i in range(rows):\n",
    "    totalpositive += y_valM[i]\n",
    "\n",
    "print(f\"Total class 1 in validation: {totalpositive} ({100*totalpositive/rows}%)\")\n",
    "\n",
    "\n",
    "# Shape\n",
    "print(f\"Training set size: {X_trainM.shape}\")\n",
    "print(f\"Validation set size: {X_valM.shape}\")\n",
    "print(f\"Test set size: {X_testM.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e32a69c2-5b46-4647-9172-c9974771b777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights: [ 0.53734166 -0.46521743 -0.86030484 -1.84474287 -0.41636978 -0.71157863\n",
      " -0.14536457 -0.51539254 -0.21343997 -0.52844822 -0.29252604 -0.33516121\n",
      "  1.12273123 -0.7750341  -1.80471966 -0.17867108  0.19880618 -0.50511489\n",
      "  1.18236944  0.21567183 -0.15535129  0.46090783 -1.36081598  0.18595913\n",
      " -0.96282072 -0.68198178 -0.00912284 -0.48069311 -1.48084612 -0.48731509\n",
      "  1.54039236]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def calculate_gradient(X_batch, y_batch, w):\n",
    "    m = len(y_batch)\n",
    "    predictions = sigmoid(X_batch @ w)\n",
    "    predictions = predictions.reshape(-1, 1)\n",
    "    error = predictions - y_batch\n",
    "    gradient = np.dot(X_batch.T, error) / m   #DeltaE(w)\n",
    "    return gradient\n",
    "\n",
    "# Mini-batch SGD for logistic regression\n",
    "def mini_batch_SGD(X, y, batchsize, stepsize, iterations):\n",
    "    m, n = X.shape  # Rows (m) and columns (n)\n",
    "    w = np.random.randn(n)\n",
    "\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        indices = np.random.permutation(m)  # random seed\n",
    "        X = X[indices]  # Shuffle according to seed\n",
    "        y = y[indices]\n",
    "\n",
    "        \n",
    "        for start in range(0, m, batchsize):\n",
    "            end = start + batchsize\n",
    "            X_batch = X[start:end]\n",
    "            y_batch = y[start:end]\n",
    "            \n",
    "            \n",
    "            gradient = calculate_gradient(X_batch, y_batch, w)\n",
    "            gradient = gradient.flatten()\n",
    "            # Update weights\n",
    "            w -= stepsize * gradient\n",
    "\n",
    "    \n",
    "    return w\n",
    "\n",
    "# Hyperparameters\n",
    "stepsize = 0.001 \n",
    "iterations = 2000\n",
    "batchsize = 25\n",
    "\n",
    "\n",
    "# Train logistic regression model with mini-batch SGD\n",
    "weights = mini_batch_SGD(X_trainM, y_trainM, batchsize, stepsize, iterations)\n",
    "print(\"Final weights:\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5b487ef6-cfaa-4959-973d-59b0d3a90950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance on Train Set:\n",
      "Accuracy: 0.9793\n",
      "Precision: 0.9792\n",
      "Recall: 0.9874\n",
      "F1-score: 0.9833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# predict values using weightvector w.\n",
    "def predict(w,X):\n",
    "    probabilities = sigmoid(X @ w)\n",
    "    return (probabilities >= 0.5).astype(int)\n",
    "\n",
    "ypredictionsTrain = predict(weights, X_trainM)\n",
    "ypredictionsTrain = ypredictionsTrain.reshape(-1, 1)\n",
    "\n",
    "#get evaluation metrics\n",
    "accuracy = accuracy_score(y_trainM, ypredictionsTrain)\n",
    "precision = precision_score(y_trainM, ypredictionsTrain)\n",
    "recall = recall_score(y_trainM, ypredictionsTrain)\n",
    "f1 = f1_score(y_trainM, ypredictionsTrain)\n",
    "\n",
    "\n",
    "print(f\"Model Performance on Train Set:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b37ee8d0-54a0-49e8-93e2-f47f3f74ac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance on Validation Set:\n",
      "Accuracy: 0.9691\n",
      "Precision: 0.9559\n",
      "Recall: 1.0000\n",
      "F1-score: 0.9774\n"
     ]
    }
   ],
   "source": [
    "ypredictionsVal = predict(weights, X_valM)\n",
    "ypredictionsVal = ypredictionsVal.reshape(-1, 1)\n",
    "\n",
    "#get evaluation metrics\n",
    "accuracy = accuracy_score(y_valM, ypredictionsVal)\n",
    "precision = precision_score(y_valM, ypredictionsVal)\n",
    "recall = recall_score(y_valM, ypredictionsVal)\n",
    "f1 = f1_score(y_valM, ypredictionsVal)\n",
    "\n",
    "\n",
    "print(f\"Model Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b2a5fe90-426a-4a7c-a825-0fa8562b6ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance on Test Set:\n",
      "Accuracy: 0.9884\n",
      "Precision: 0.9818\n",
      "Recall: 1.0000\n",
      "F1-score: 0.9908\n"
     ]
    }
   ],
   "source": [
    "ypredictionsTest = predict(weights, X_testM)\n",
    "ypredictionsTest = ypredictionsTest.reshape(-1, 1)\n",
    "\n",
    "#get evaluation metrics\n",
    "accuracy = accuracy_score(y_testM, ypredictionsTest)\n",
    "precision = precision_score(y_testM, ypredictionsTest)\n",
    "recall = recall_score(y_testM, ypredictionsTest)\n",
    "f1 = f1_score(y_testM, ypredictionsTest)\n",
    "\n",
    "\n",
    "print(f\"Model Performance on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9852414-37c8-4e6d-913f-b89474ccd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Here the recall metric is very accurate, which is super important when it comes to diagnosis of breast cancer. \n",
    "##  This means that almost no patients with breast cancer get a negative result when conducting the test = almost no false negatives\n",
    "##  Precition is not as important but the metric is still good, the test is very accurate with 98% precition on the test data. \n",
    "##  It is fortunate that we got even better results on test data than on the train data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
